{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.preprocessing.image as kim\n",
    "from shutil import copyfile\n",
    "from scipy.misc import imsave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_directory = ''\n",
    "t_path = 'train'\n",
    "v_path = 'train'\n",
    "augmented_t_path = 'pretrained_test/augmented_train_final1/'\n",
    "augmented_v_path = 'pretrained_valid/augmented_valid_final/'\n",
    "image_height = 128\n",
    "image_width = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_fr = df.groupby(\"Id\",as_index = False)[\"Image\"].count()\n",
    "cls_fr = cls_fr.rename(columns = {\"Image\":\"count_image\"})\n",
    "cls_fr=cls_fr.sort_values('count_image')\n",
    "cls_fr=cls_fr[['Id','count_image']].query('Id!=\"new_whale\"')\n",
    "df2=cls_fr.tail(20)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lst=[]\n",
    "lst=df2['Id']\n",
    "for x in lst:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class_dictionary = convert_dict('train.csv') #class_dictionary == label map\n",
    "classes = set(class_dictionary.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_dict(l_file):\n",
    "    dictionary = {}  \n",
    "    with open(l_file, 'r') as lab_file:\n",
    "        _ = lab_file.readline()  \n",
    "        for line in lab_file:\n",
    "            whale_name, whale_class = line.strip().split(',')\n",
    "            dictionary[whale_] = whale_class\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in classes:\n",
    "    sub_folder = os.path.join('training_dataset/', cls)\n",
    "    if not os.path.exists(sub_folder):\n",
    "        os.mkdir(sub_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_related_classes(path1,path2):\n",
    "    for wanted_folders in lst:\n",
    "        directry=os.path.join(path1,wanted_folders)\n",
    "        shutil.move(directry, path2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p1='training_dataset/'\n",
    "p2='training_dataset_30'\n",
    "moving_related_classes(p1,p2)\n",
    "p3='validation'\n",
    "p4='validation_30'\n",
    "moving_related_classes(p3,p4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train='train/train'\n",
    "whale_images = os.listdir(train)  #whale images=image names\n",
    "for img_1 in whale_images:\n",
    "    image_file = os.path.join(train, img_1)\n",
    "    if os.path.isfile(image_file):\n",
    "        img = resize_img(image_file, dim=(image_height, image_width))\n",
    "    \n",
    "        label = class_dictionary[img_1]\n",
    "        if len(os.listdir(os.path.join('training_dataset/', label))) <14:\n",
    "            cur_lab_cnt = len(os.listdir(os.path.join('training_dataset/', label)))\n",
    "            save_name = str(cur_lab_cnt + 1) + '.jpg'\n",
    "            imsave(os.path.join(base_data_path,'training_dataset/', label, save_name), img)\n",
    "        else:\n",
    "            cur_cnt = len(os.listdir(os.path.join('validation/', label)))\n",
    "            save_name = str(cur_cnt + 1) + '.jpg'\n",
    "            imsave(os.path.join('validation/', label, save_name), img) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(file_path, dim=None):\n",
    "    x = np.array(imread(file_path), dtype=np.float32)\n",
    "    if len(x.shape) < 3 or x.shape[-1] < 3:\n",
    "        x = np.squeeze(x)\n",
    "        x = np.stack((x,) * 3, axis=-1)\n",
    "    elif x.shape[-1] > 3:\n",
    "        x = x[:, :, :3]  \n",
    "    if dim is not None:\n",
    "        x = imresize(x, dim)\n",
    "    x = x / 255\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def aug_rotate(img_array, n=6, angle=10):\n",
    "    aug1 = [ker.random_rotation(img_array, angle,row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')for _ in range(n)]   \n",
    "    return aug1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_shear(img_array, n=6):\n",
    "    aug2 = [ker.random_shear(img_array, intensity=7, \n",
    "                        row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "                        for _ in range(n)]\n",
    "    return aug2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def aug_zoom(img_array, n=6,wt=1.5, ht=0.8):\n",
    "    aug3 = [kim.random_zoom(img_array, zoom_range=(wt, ht), row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "                        for _ in range(n)]    \n",
    "    return aug3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_shift(img_array, n=6):\n",
    "    aug4 = [ker.random_shift(img_array, wrg=0.1, hrg=0.2, \n",
    "                        row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "                        for _ in range(n)]\n",
    "    \n",
    "    return aug4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.preprocessing.image as kim\n",
    "from shutil import copyfile\n",
    "from scipy.misc import imsave\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_images(path, num_iterations=4):\n",
    "    no_img=60\n",
    "    preprocessing = [aug_rotate,aug_shift, aug_shear, aug_zoom]\n",
    "    labels = os.listdir(path)\n",
    "    counter_label = 1\n",
    "    for label in labels:\n",
    "        class_path = os.path.join(path, label)\n",
    "        for i in preprocessing:\n",
    "            images = os.listdir(class_path)\n",
    "            cnt = len(images) + 1            \n",
    "            for image in images:\n",
    "                img_name = os.path.join(class_path, image)\n",
    "                image_array = cv2.imread(img_name)\n",
    "                pre_img = i(image_array, num_iterations)               \n",
    "                for kth_img in pre_img:\n",
    "                    if cnt > no_img:\n",
    "                        break\n",
    "                    imsave(os.path.join(class_path, str(cnt)+'.jpg'), kth_img)\n",
    "                    cnt += 1\n",
    "        counter_label += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_images(augmented_t_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "size_of_batch=32\n",
    "im_col=128\n",
    "im_row=128\n",
    "im_shape=(im_row,im_col,3)\n",
    "\n",
    "epochs=iterations\n",
    "augmented_t_path = 'cnn_basic_noprepro/augmented_train_final1/'\n",
    "augmented_v_path = 'cnn_basic_noprepro/augmented_valid_final/'\n",
    "#check here tomorrow\n",
    "T_Data = ImageDataGenerator(\n",
    "        rescale=1./255)\n",
    "Test_gen = ImageDataGenerator(rescale=1./255)\n",
    "t_images = T_Data.flow_from_directory(\n",
    "        'cnn_basi c_noprepro/augmented_train_final1/',target_size=(128, 128),\n",
    "        batch_size=size_of_batch,\n",
    "        class_mode='categorical')\n",
    "\n",
    "v_images = Test_gen.flow_from_directory(\n",
    "        'cnn_basic_noprepro/augmented_valid_final/',target_size=(128, 128),\n",
    "        batch_size=size_of_batch,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_images[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_batch = 32\n",
    "number_of_samples = 100\n",
    "v_steps = 5\n",
    "filter1 = 32\n",
    "filter2 = 64\n",
    "conv_layer_1_size = 3\n",
    "conv_layer_2_size = 2\n",
    "pooling = 3\n",
    "classes_num = 30\n",
    "rateOfLearning = 0.001\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "iterations= 20;\n",
    "v_images[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasicCNNModel = Sequential()\n",
    "BasicCNNModel.add(Convolution2D(filter1, conv_layer_1_size, conv_layer_1_size, border_mode =\"same\", input_shape=(im_col, im_row, 3),name=\"Convolution_layer_1\"))\n",
    "BasicCNNModel.add(Activation(\"relu\"))\n",
    "BasicCNNModel.add(MaxPooling2D(pool_size=(pooling, pooling),name=\"Maxpooling_layer_1\"))\n",
    "\n",
    "BasicCNNModel.add(Convolution2D(filter2, conv_layer_2_size, conv_layer_2_size, border_mode =\"same\",name=\"Convolution_layer_2\"))\n",
    "BasicCNNModel.add(Activation(\"relu\"))\n",
    "BasicCNNModel.add(MaxPooling2D(pool_size=(pooling, pooling), dim_ordering='th',name=\"Maxpooling_layer_2\"))\n",
    "\n",
    "BasicCNNModel.add(Flatten())\n",
    "BasicCNNModel.add(Dense(256,name=\"Dense_layer_1\"))\n",
    "BasicCNNModel.add(Activation(\"relu\"))\n",
    "BasicCNNModel.add(Dropout(0.5))\n",
    "BasicCNNModel.add(Dense(classes_num, activation='softmax',name=\"Dense_layer_2\"))\n",
    "\n",
    "BasicCNNModel.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=rateOfLearning),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e715bddd2eff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m T_Data = ImageDataGenerator(\n\u001b[0m\u001b[1;32m      2\u001b[0m     rescale=1. / 255)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "T_Data = ImageDataGenerator(\n",
    "    rescale=1. / 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data = ImageDataGenerator(rescale=1. / 255)\n",
    "augmented_t_path = 'cnn_basic_noprepro/augmented_train_final1/'\n",
    "augmented_v_path = 'cnn_basic_noprepro/augmented_valid_final/'\n",
    "t_images = T_Data.flow_from_directory(\n",
    "    augmented_t_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=size_of_batch,\n",
    "    class_mode='categorical')\n",
    "\n",
    "v_images = Test_data.flow_from_directory(\n",
    "    augmented_v_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=size_of_batch,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasicCNNModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard=TensorBoard(\n",
    "    log_dir=r'logs\\{}'.format('2ndLayer'),\n",
    "    write_graph=True,\n",
    "    write_grads=True,\n",
    "    write_images=True\n",
    ")\n",
    "PlotInfo=BasicCNNModel.fit_generator(\n",
    "    t_images,\n",
    "    samples_per_epoch=number_of_samples,\n",
    "    epochs=iterations,\n",
    "    validation_data=v_images,\n",
    "    validation_steps=v_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = './models/'\n",
    "if not os.path.exists(target_dir):\n",
    "  os.mkdir(target_dir)\n",
    "BasicCNNModel.save('./models/model.h5')\n",
    "BasicCNNModel.save_weights('./models/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c=train_generator.class_indices\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "file=r'C:\\Users\\pooja\\AnacondaProjects\\ML project\\test\\w_f19faeb_1.jpg'\n",
    "x = load_img(file, target_size=(img_width,img_height))\n",
    "x = img_to_array(x)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "array = BasicCNNModel.predict(x)\n",
    "ind = np.unravel_index(np.argmax(array, axis=None), array.shape)\n",
    "print(list(c.keys())[list(c.values()).index(ind[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BasicCNNModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PlotInfo.history['acc'])\n",
    "plt.plot(PlotInfo.history['val_acc'])\n",
    "plt.title('ACCURACY')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(PlotInfo.history['loss'])\n",
    "plt.plot(PlotInfo.history['val_loss'])\n",
    "plt.title('LOSS')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
